{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Barly/Anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import types\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import confusion_matrix, log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "from sklearn import svm\n",
    "import codecs, csv, sys\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB                                                                \n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading the csv containg embedding for test and train embedding data\n",
    "df_train = pd.read_csv(\"/Volumes/Barly/NLP/Project/5k_testing/Type3/data/doc2Vec/train_doc2vec_pretrained.csv\")\n",
    "df_test = pd.read_csv(\"/Volumes/Barly/NLP/Project/5k_testing/Type3/data/doc2Vec/test_doc2vec_pretrained.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenating the embeddings for question1 and question 2 and normalizing before passing it to classifiers\n",
    "start_time = time.time()\n",
    "\n",
    "train_embedding1 = map(np.fromstring, df_train['embedding_1'],\\\n",
    "                                      itertools.repeat(float, df_train.shape[0]),\\\n",
    "                                                       itertools.repeat(300, df_train.shape[0]))\n",
    "\n",
    "train_embedding2 = map(np.fromstring, df_train['embedding_2'],\\\n",
    "                                      itertools.repeat(float, df_train.shape[0]),\\\n",
    "                                                       itertools.repeat(300, df_train.shape[0]))\n",
    "\n",
    "X_label = np.array(df_train['is_duplicate'].tolist())\n",
    "X_train = np.concatenate((np.array(train_embedding1), np.array(train_embedding2)), axis=1)\n",
    "normalize = Normalizer().fit(X_train)\n",
    "X_train = normalize.transform(X_train)\n",
    "\n",
    "test_embedding1 = map(np.fromstring, df_test['embedding_1'],\\\n",
    "                                      itertools.repeat(float, df_test.shape[0]),\\\n",
    "                                                       itertools.repeat(300, df_test.shape[0]))\n",
    "\n",
    "test_embedding2 = map(np.fromstring, df_test['embedding_2'],\\\n",
    "                                      itertools.repeat(float, df_test.shape[0]),\\\n",
    "                                                       itertools.repeat(300, df_test.shape[0]))\n",
    "\n",
    "Y_label = np.array(df_test['is_duplicate'].tolist())\n",
    "Y_train = np.concatenate((np.array(test_embedding1), np.array(test_embedding2)), axis=1) # concatenating the embedding for question 1 and question2\n",
    "Y_train = normalize.transform(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting is_duplicate value by passing embedding into shallow classifiers\n",
    "def naive_bayes(x_train_matrix, x_test_matrix, y_train, y_test):    #NAIVE BAYERS MODEL                                                                \n",
    "    nb = MultinomialNB(alpha=2.8)\n",
    "    nb.fit(x_train_matrix, y_train)                                 #train the model\n",
    "    y_pred = nb.predict(x_test_matrix)                              #make predictions for X_test\n",
    "    print (\"Naive Bayes Model score: \" + str(accuracy_score(y_test, y_pred)))         \n",
    "    print (\"Naive Bayes Model confusion matrix:\")\n",
    "    print (confusion_matrix(y_test, y_pred))\n",
    "    y_predicted_proba = nb.predict_proba(x_test_matrix)\n",
    "    print log_loss(y_test, y_predicted_proba)\n",
    "    return y_pred\n",
    "\n",
    "def logistic_regression(x_train_matrix, x_test_matrix, y_train, y_test): \n",
    "    logReg = LogisticRegressionCV(Cs=[0.01, 0.1, 1, 10, 100], cv=5, solver='saga', n_jobs= -1 )\n",
    "    logReg.fit(x_train_matrix, y_train)\n",
    "    y_pred_log = logReg.predict(x_test_matrix)\n",
    "    print (\"Logistic Regression score: \"+ str(accuracy_score(y_test, y_pred_log)))\n",
    "    print (\"Logistic Regression confusion matrix:\")\n",
    "    print (confusion_matrix(y_test, y_pred_log))\n",
    "    y_predicted_proba = logReg.predict_proba(x_test_matrix)\n",
    "    print log_loss(y_test, y_predicted_proba)\n",
    "    return y_pred_log\n",
    "\n",
    "def linear_svm(x_train_matrix, x_test_matrix, y_train, y_test):\n",
    "    \n",
    "    param_grid = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']}]\n",
    "    svc = svm.SVC()\n",
    "    svm1 = GridSearchCV(estimator=svc, param_grid=param_grid, n_jobs= -1, cv = 5) \n",
    "    svm1.fit(x_train_matrix, y_train)\n",
    "    y_pred_svc = svm1.predict(x_test_matrix)\n",
    "    print (\"SVC score: \" + str(accuracy_score(y_test, y_pred_svc)))\n",
    "    print (\"SVC confusionmatrix:\")\n",
    "    print (confusion_matrix(y_test, y_pred_svc))\n",
    "    return y_pred_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- start -> preprocessing:18.0743200779 seconds ---\n",
      "\n",
      "\n",
      " Naive bayes result on doc2vec_embedding: \n",
      "Naive Bayes Model score: 0.484\n",
      "Naive Bayes Model confusion matrix:\n",
      "[[213  37]\n",
      " [221  29]]\n",
      "0.696761963957\n",
      "--- preprocessing -> naive bayes :0.0218510627747 seconds ---\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      " Logistic Regression result on doc2vec_embedding: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Barly/Anaconda2/lib/python2.7/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score: 0.472\n",
      "Logistic Regression confusion matrix:\n",
      "[[197  53]\n",
      " [211  39]]\n",
      "0.695261293329\n",
      "--- naive bayes -> logistic regression :16.1554670334 seconds ---\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      " Linear SVM result on doc2vec_embedding: \n",
      "SVC score: 0.474\n",
      "SVC confusionmatrix:\n",
      "[[211  39]\n",
      " [224  26]]\n",
      "--- logistic regression -> linear svm :189.580327988 seconds ---\n",
      "--- TOTAL TIME: 223.832290173 seconds ---\n"
     ]
    }
   ],
   "source": [
    "preprocessing_time = time.time()\n",
    "print(\"--- start -> preprocessing:%s seconds ---\" % (preprocessing_time - start_time))\n",
    "\n",
    "\n",
    "print (\"\\n\\n Naive bayes result on doc2vec_embedding: \")\n",
    "y_pred_nb = naive_bayes(X_train, Y_train, X_label, Y_label)\n",
    "naive_bayes_time = time.time() \n",
    "print(\"--- preprocessing -> naive bayes :%s seconds ---\" % (naive_bayes_time - preprocessing_time))\n",
    "\n",
    "\n",
    "print (\"-------------------------------------------\")\n",
    "print (\"\\n\\n Logistic Regression result on doc2vec_embedding: \")\n",
    "y_pred_lr = logistic_regression(X_train, Y_train, X_label, Y_label)\n",
    "logistic_regression_time = time.time()\n",
    "print(\"--- naive bayes -> logistic regression :%s seconds ---\" % (logistic_regression_time - naive_bayes_time))\n",
    "\n",
    "\n",
    "print (\"-------------------------------------------\")\n",
    "print (\"\\n\\n Linear SVM result on doc2vec_embedding: \")\n",
    "y_pred_svm = linear_svm(X_train, Y_train, X_label, Y_label)\n",
    "linear_svm_time = time.time()\n",
    "print(\"--- logistic regression -> linear svm :%s seconds ---\" % (linear_svm_time - logistic_regression_time))\n",
    "print(\"--- TOTAL TIME: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_nb = y_pred_nb.tolist()\n",
    "y_pred_lr = y_pred_lr.tolist()\n",
    "y_pred_svm = y_pred_svm.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test['nb_duplicate'] = y_pred_nb\n",
    "df_test['lr_duplicate'] = y_pred_lr\n",
    "df_test['svm_duplicate'] = y_pred_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.to_csv(\"/Volumes/Barly/NLP/Project/5k_testing/Type3/Results/test_doc2vec_classifier_pretrained.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Comparing the cosine similarity between vectors on different thresholds\n",
    "df_new = pd.read_csv(\"/Volumes/Barly/NLP/Project/5k_testing/Type3/data/doc2Vec/test_doc2vec_classifier_pretrained.csv\")\n",
    "\n",
    "def conv(elem):\n",
    "    a = re.compile(r\"[-+]?\\d*\\.\\d+|\\d+\")\n",
    "    return re.findall(a, elem)[0]\n",
    "\n",
    "threshold_list = [0.2, 0.29, 0.3,0.35, 0.37, 0.39,0.4,0.5,0.6, 0.7]\n",
    "df_cos_test = df_new\n",
    "df_cos_test['cos'] = map(conv, df_cos_test['cos'])\n",
    "df_cos_test['cos'] = df_cos_test['cos'].apply(pd.to_numeric)\n",
    "\n",
    "target_names = [0,1]\n",
    "for threshold in threshold_list:\n",
    "    \n",
    "    print \"Threshold: \", threshold\n",
    "    \n",
    "    df_cos_test['thre_'+str(threshold)] = np.where(df_cos_test['cos']>=threshold, 1, 0)\n",
    "\n",
    "    print confusion_matrix(df_cos_test['is_duplicate'], df_cos_test['thre_'+str(threshold)]\\\n",
    "                                      , labels=target_names).ravel()\n",
    "    \n",
    "    print classification_report(df_cos_test['is_duplicate'], df_cos_test['thre_'+str(threshold)])\n",
    "\n",
    "    print \"Accuracy: \" ,accuracy_score(df_cos_test['is_duplicate'], df_cos_test['thre_'+str(threshold)])\n",
    "    print \"\\n*******************\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
